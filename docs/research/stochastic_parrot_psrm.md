---
title: Ornstein, Blasingame, and Truscott (2025)
parent: Research Projects
nav_order: 3
---

# How to Train Your Stochastic Parrot: _Large Language Models for Political Texts_
**Jake S. Truscott** <br>
*Political Science Research and Methods* (2025)

<br>

**Abstract**: We demonstrate how few-shot prompts to large language models (LLMs) can be effectively applied to a
wide range of text-as-data tasks in political science - including sentiment analysis, document scaling, and
topic modeling. In a series of pre-registered analyses, this approach outperforms conventional supervised
learning methods without the need for extensive data pre-processing or large sets of labeled training data.
Performance is comparable to expert and crowd-coding methods at a fraction of the cost. We propose a set
of best practices for adapting these models to social science measurement tasks, and develop an opensource software package for researchers.

---

Citation: Ornstein, J. T., Blasingame, E. N., & Truscott, J. S. (2025). How to train your stochastic parrot: Large language models for political texts. Political Science Research and Methods, 13(2), 264-281. <br>

<a href="{{ site.baseurl }}/assets/papers_figures_tables/stochastic_parrot_psrm/stochastic_parrot.pdf" download>
  <button style="padding: 8px 16px; background-color:rgb(255, 255, 255); color: black; border: black; border-radius: 4px;">
    Download Paper
  </button>
</a>
<br>


---

## Classification Performance on Twitter Sentiment Compared to Alternative Strategies


<img src="{{ site.baseurl }}/assets/papers_figures_tables/stochastic_parrot_psrm/Figure_2.png" alt="Classification Performance on Twitter Sentiment Compared to Alternative Strategies (Figure 2)" width="600" />

